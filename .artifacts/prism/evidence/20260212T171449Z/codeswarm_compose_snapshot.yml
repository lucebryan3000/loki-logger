# Expected naming: COMPOSE_PROJECT_NAME=vllm_${VLLM_PROFILE} (set via env/scripts).
# Unified runtime container name (post-collapse): codeswarm-mcp
services:
  codeswarm-mcp:
    # Compose loads .env by default; overrides can be exported at runtime.
    # Profile knobs (defaults map to fast_executor):
    # - VLLM_PROFILE: fast_executor|patient_executor|overnight_validator|experimental_edge
    # - VLLM_IMAGE: pinned image tag (avoid latest)
    # - VLLM_PORT: API port binding
    # - VLLM_MODEL_ID: model selection
    # - VLLM_GPU_MEM_UTIL / VLLM_MAX_MODEL_LEN / VLLM_MAX_NUM_SEQS: sizing
    # - VLLM_RESTART_POLICY: unless-stopped (fast/patient), "no" (overnight/experimental)
    # - HF_CACHE_DIR: Hugging Face cache directory
    image: codeswarm-mcp
    build:
      context: .
      dockerfile: Dockerfile
    container_name: codeswarm-mcp
    restart: ${VLLM_RESTART_POLICY:-unless-stopped}
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "14"
    entrypoint: ["sh", "-lc"]
    ports:
      # vLLM HTTP API + Swagger/OpenAPI UI.
      # Default is loopback-only; set VLLM_PUBLISH_HOST=0.0.0.0 to expose on LAN.
      - "${VLLM_PUBLISH_HOST:-127.0.0.1}:${VLLM_PORT:-8000}:8000"
      # MCP HTTP port (streamable-http). Keep loopback-only unless you explicitly mean to
      # expose filesystem+exec tools beyond this host.
      - "${MCP_PUBLISH_HOST:-127.0.0.1}:${MCP_HTTP_PORT:-3100}:3100"
    ipc: host
    environment:
      # Single-dev ergonomics: rotating passcode mode uses container local time.
      # Pin TZ so "HH local" matches the operator's mental model (CST/CDT via America/Chicago).
      - TZ=${TZ:-America/Chicago}
      # Publishing posture (host-side, used for MCP origin policy). Default is loopback-only.
      - PUBLISH_HOST=${MCP_PUBLISH_HOST:-127.0.0.1}
      - HF_TOKEN
      - VLLM_MODEL_ID
      - VLLM_PORT
      - VLLM_GPU_MEM_UTIL
      - VLLM_MAX_MODEL_LEN
      - VLLM_MAX_NUM_SEQS
      - VLLM_TOOL_CALL_PARSER
      - VLLM_QUANTIZATION_REQUIRED
      - VLLM_QUANTIZATION
      - VLLM_ENABLE_PREFIX_CACHING
      - VLLM_ENFORCE_EAGER
      - VLLM_MAX_NUM_BATCHED_TOKENS
      # Embedded MCP server (Node, streamable-http).
      - NODE_ENV=production
      - MCP_TRANSPORT=http
      - MCP_HTTP_PORT=3100
      - MCP_HTTP_HOST=0.0.0.0
      # Origin allowlist is for DNS rebinding protection, not authentication.
      - MCP_ALLOWED_ORIGINS=http://localhost,http://localhost:*,http://127.0.0.1,http://127.0.0.1:*
      - MCP_ALLOW_NO_ORIGIN=true
      # If ports are published beyond loopback, require explicit opt-in for permissive origin settings.
      - MCP_PERMISSIVE_ORIGINS=${MCP_PERMISSIVE_ORIGINS:-false}
      # Baseline: do not require authentication for MCP.
      - MCP_REQUIRE_AUTH=false
      # Phase 1: Passcode gate (tool-layer, external-only).
      # Active when either:
      # - MCP_PSK_HASH is set (static passcode hash), OR
      # - MCP_PSK_BASE is set (rotating local-time passcode, low-friction single-dev mode).
      - MCP_PSK_HASH=${MCP_PSK_HASH}
      - MCP_PSK_BASE=${MCP_PSK_BASE:-}
      - MCP_PSK_ROTATION_MODE=${MCP_PSK_ROTATION_MODE:-hh12_local}
      - MCP_PSK_ROTATION_SKEW_SLOTS=${MCP_PSK_ROTATION_SKEW_SLOTS:-1}
      - MCP_UNLOCK_TTL_SECONDS=${MCP_UNLOCK_TTL_SECONDS:-3600}
      # Session/unlock ergonomics (Phase 1):
      # - MCP_SESSION_FALLBACK_MODE: ip_ua|ua|global (default ip_ua)
      # - MCP_UNLOCK_SCOPE: session|global (default session)
      - MCP_SESSION_FALLBACK_MODE=${MCP_SESSION_FALLBACK_MODE:-ip_ua}
      - MCP_UNLOCK_SCOPE=${MCP_UNLOCK_SCOPE:-session}
      # Default to external-only access logging to avoid flooding Docker logs with local polling (~5 req/s is common).
      # For debugging, override with MCP_LOG_EXTERNAL_ONLY=false in your environment or .env and recreate the container.
      - MCP_LOG_EXTERNAL_ONLY=${MCP_LOG_EXTERNAL_ONLY:-true}
      # Auto-heal/escalation daemons (Prompt-14/15).
      - ENABLE_AUTOHEAL=${ENABLE_AUTOHEAL:-false}
      - ENABLE_ESCALATION=${ENABLE_ESCALATION:-false}
      - MCP_DEBUG=${MCP_DEBUG:-false}
      - MCP_LOG_LEVEL=${MCP_LOG_LEVEL:-info}
      - MCP_LOG_DIR=/logs/mcp
      - MCP_LOG_TO_FILE=${MCP_LOG_TO_FILE:-true}
      # Docker tool capability controls.
      - MCP_ENABLE_DOCKER=${MCP_ENABLE_DOCKER:-true}
      - MCP_DOCKER_PROBE_TTL_MS=${MCP_DOCKER_PROBE_TTL_MS:-15000}
      - OPENCODE_WORKSPACE=/workspace
      # When MCP is co-located with vLLM, use in-container loopback (no Docker DNS).
      - VLLM_BASE_URL=http://127.0.0.1:8000
      - VLLM_MODEL=${VLLM_MODEL_ID:-Qwen/Qwen2.5-Coder-1.5B-Instruct}
    volumes:
      # HF cache directory (set HF_CACHE_DIR, derived from MODELS_DIR).
      - "${HF_CACHE_DIR:-./models/.hf-cache}:/root/.cache/huggingface"
      - ./models:/models
      # MCP workspace + logs (keeps baseline behavior parity with the legacy container).
      - ${OPENCODE_WORKSPACE:-/home/luce/apps/vLLM}:/workspace:${WORKSPACE_MOUNT_MODE:-rw}
      # Workspace switching mount (host /home/luce/apps -> container /workspaces).
      - /home/luce/apps:/workspaces:rw
      - mcp-logs:/logs:rw
      # Enable Docker MCP tool access to host Docker daemon.
      - /var/run/docker.sock:/var/run/docker.sock
    # GPU access (compose on this host accepts deploy.resources.reservations.devices).
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    command:
      - |
        set -eu

        # Runtime state directory (for request/marker files).
        mkdir -p /var/run/codeswarm-mcp

        # Git safety: /workspace is a bind mount and may appear "dubious" to git inside containers.
        # Allow git tools to operate without requiring manual safe.directory configuration.
        git config --global --add safe.directory /workspace 2>/dev/null || true

        # Security posture: if publishing beyond loopback, default to strict origin behavior unless
        # MCP_PERMISSIVE_ORIGINS=true is explicitly set.
        if [ "$${PUBLISH_HOST:-127.0.0.1}" != "127.0.0.1" ] && [ "$${MCP_PERMISSIVE_ORIGINS:-false}" != "true" ]; then
          export MCP_ALLOW_NO_ORIGIN=false;
          export MCP_ALLOWED_ORIGINS=http://127.0.0.1,http://localhost;
          echo "[codeswarm-mcp] Origin policy: strict (PUBLISH_HOST=$${PUBLISH_HOST:-} MCP_PERMISSIVE_ORIGINS=$${MCP_PERMISSIVE_ORIGINS:-})";
        else
          echo "[codeswarm-mcp] Origin policy: permissive (PUBLISH_HOST=$${PUBLISH_HOST:-} MCP_PERMISSIVE_ORIGINS=$${MCP_PERMISSIVE_ORIGINS:-})";
        fi

        echo "[codeswarm-mcp] Starting embedded MCP (Node, http transport)...";
        node /mcp/server.js http &
        MCP_PID="$$!";
        echo "[codeswarm-mcp] Embedded MCP pid=$${MCP_PID}";

        AUTOHEAL_PID="";
        if [ "$${ENABLE_AUTOHEAL:-false}" = "true" ]; then
          echo "[codeswarm-mcp] Starting auto-heal daemon (bounded, disable-on-loop)...";
          python3 /health/autoheal_daemon.py &
          AUTOHEAL_PID="$$!";
          echo "[codeswarm-mcp] Auto-heal pid=$${AUTOHEAL_PID}";
        else
          echo "[codeswarm-mcp] Auto-heal disabled (ENABLE_AUTOHEAL=$${ENABLE_AUTOHEAL:-})";
        fi

        ESCALATION_PID="";
        if [ "$${ENABLE_ESCALATION:-false}" = "true" ]; then
          echo "[codeswarm-mcp] Starting escalation daemon (inert unless auto-heal disabled)...";
          python3 /health/escalation_daemon.py &
          ESCALATION_PID="$$!";
          echo "[codeswarm-mcp] Escalation pid=$${ESCALATION_PID}";
        else
          echo "[codeswarm-mcp] Escalation disabled (ENABLE_ESCALATION=$${ENABLE_ESCALATION:-})";
        fi
        PROBE_PID="";
        if [ "$${ENABLE_LLM_PROBES:-true}" = "true" ]; then
          echo "[codeswarm-mcp] Starting internal LLM probe daemon (observational only)...";
          python3 /health/llm_probe_daemon.py &
          PROBE_PID="$$!";
          echo "[codeswarm-mcp] LLM probe pid=$${PROBE_PID}";
        else
          echo "[codeswarm-mcp] LLM probes disabled (ENABLE_LLM_PROBES=$${ENABLE_LLM_PROBES:-})";
        fi
        cleanup() { if [ -n "$${PROBE_PID}" ]; then echo "[codeswarm-mcp] Stopping probe pid=$${PROBE_PID}"; kill "$${PROBE_PID}" 2>/dev/null || true; wait "$${PROBE_PID}" 2>/dev/null || true; echo "[codeswarm-mcp] Probe stopped"; fi; if [ -n "$${ESCALATION_PID}" ]; then echo "[codeswarm-mcp] Stopping escalation pid=$${ESCALATION_PID}"; kill "$${ESCALATION_PID}" 2>/dev/null || true; wait "$${ESCALATION_PID}" 2>/dev/null || true; echo "[codeswarm-mcp] Escalation stopped"; fi; if [ -n "$${AUTOHEAL_PID}" ]; then echo "[codeswarm-mcp] Stopping auto-heal pid=$${AUTOHEAL_PID}"; kill "$${AUTOHEAL_PID}" 2>/dev/null || true; wait "$${AUTOHEAL_PID}" 2>/dev/null || true; echo "[codeswarm-mcp] Auto-heal stopped"; fi; echo "[codeswarm-mcp] Stopping embedded MCP pid=$${MCP_PID}"; kill "$${MCP_PID}" 2>/dev/null || true; wait "$${MCP_PID}" 2>/dev/null || true; echo "[codeswarm-mcp] Embedded MCP stopped"; };
        trap cleanup INT TERM EXIT;
        if [ "$${VLLM_QUANTIZATION_REQUIRED:-}" = "true" ] && [ -z "$${VLLM_QUANTIZATION:-}" ]; then echo "ERROR: VLLM_QUANTIZATION_REQUIRED=true but VLLM_QUANTIZATION is unset" >&2; exit 1; fi;
        # vLLM binds to a fixed in-container port (8000). VLLM_PORT controls host publishing only (ports: ...:${VLLM_PORT}:8000).
        vllm serve $${VLLM_MODEL_ID:-Qwen/Qwen2.5-Coder-1.5B-Instruct} --host 0.0.0.0 --port 8000 --gpu-memory-utilization $${VLLM_GPU_MEM_UTIL:-0.40} --max-model-len $${VLLM_MAX_MODEL_LEN:-1024} --max-num-seqs $${VLLM_MAX_NUM_SEQS:-8} --enable-auto-tool-choice --tool-call-parser $${VLLM_TOOL_CALL_PARSER:-hermes} $${VLLM_ENABLE_PREFIX_CACHING:+--enable-prefix-caching} $${VLLM_ENFORCE_EAGER:+--enforce-eager} $${VLLM_MAX_NUM_BATCHED_TOKENS:+--max-num-batched-tokens $${VLLM_MAX_NUM_BATCHED_TOKENS}} $${VLLM_QUANTIZATION:+--quantization $${VLLM_QUANTIZATION}}

volumes:
  mcp-logs:
    driver: local
